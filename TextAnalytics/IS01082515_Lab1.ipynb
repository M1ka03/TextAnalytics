{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e411c439-bda5-46c2-a9e7-ac234e4d734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Text:\n",
      " Hello, this is a sample text file.\n",
      "This is the second line.\n"
     ]
    }
   ],
   "source": [
    "# Read the content of the text file\n",
    "with open('sample.txt', 'r', encoding='utf-8') as file:\n",
    " text_data = file.read()\n",
    "print(\"Raw Text:\\n\", text_data)\n",
    "# Store in another file\n",
    "with open('stored_text.txt', 'w', encoding='utf-8') as file:\n",
    " file.write(text_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b01d378-f6dc-4226-8631-69c28a46275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07317da1-5b4d-40f8-85ce-28cf963238c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews:\n",
      " 0    The product is amazing!\n",
      "1     Worst experience ever!\n",
      "2              Wow sooo good\n",
      "Name: Review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('reviews.csv')\n",
    "print(\"Reviews:\\n\", df['Review'].head())\n",
    "# Save the reviews column to a text file\n",
    "df['Review'].to_csv('stored_reviews.txt', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a9653d-a303-4d4f-8559-2424b30b1648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two rows:\n",
      "    ID                   Review\n",
      "0   1  The product is amazing!\n",
      "1   2   Worst experience ever!\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "df_excel = pd.read_excel('reviews.xlsx', engine='openpyxl')\n",
    "print(\"First two rows:\\n\", df_excel.head(2))\n",
    "# Save the first two rows to a text file\n",
    "df_excel.head(2).to_csv('extracted_excel.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d69004d-6dcf-456e-937a-71e301854ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3972d90f-9a71-4384-854c-c3bf948fb499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted City: New York\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open('social_data.json', 'r', encoding='utf-8') as file:\n",
    " data = json.load(file)\n",
    "print(\"Extracted City:\", data['city'])\n",
    "# Store the extracted city to a file\n",
    "with open('stored_city.txt', 'w', encoding='utf-8') as file:\n",
    " file.write(data['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e51d7e-ee6c-41f4-a560-f0e9593ec200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ab2e60e-b70e-4a41-8563-3e82f5ae0feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 9 (3263701309.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    title = article.find('title').text\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 9\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML file\n",
    "tree = ET.parse('news.xml')\n",
    "root = tree.getroot()\n",
    "for article in root.findall('article'):\n",
    " title = article.find('title').text\n",
    " print(\"Extracted Title:\", title)\n",
    "# Store the extracted title to a file\n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file:\n",
    " for article in root.findall('article'):\n",
    " title = article.find('title').text\n",
    " file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72027813-5662-4e07-b1c6-4ed1f4e5bdcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 4 (1152472590.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    title = article.find('title').text\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 4\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML file\n",
    "tree = ET.parse('news.xml')\n",
    "root = tree.getroot()\n",
    "for article in root.findall('article'):\n",
    "title = article.find('title').text\n",
    " print(\"Extracted Title:\", title)\n",
    "# Store the extracted title to a file\n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file:\n",
    " for article in root.findall('article'):\n",
    "     title = article.find('title').text\n",
    " file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "785430c2-f7e9-4b96-8968-20e9a0eafb52",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:6\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"Extracted Title:\", title)\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Parse the XML file\n",
    "tree = ET.parse('news.xml')\n",
    "root = tree.getroot()\n",
    "for article in root.findall('article'):\n",
    "     title = article.find('title').text\n",
    " print(\"Extracted Title:\", title)\n",
    "# Store the extracted title to a file\n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file:\n",
    " for article in root.findall('article'):\n",
    "     title = article.find('title').text\n",
    "     file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df8304e0-5daa-4f58-97e3-501b8bb61f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Title: AI is transforming industries\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "# Parse the XML file\n",
    "tree = ET.parse('news.xml')\n",
    "root = tree.getroot()\n",
    "for article in root.findall('article'):\n",
    " title = article.find('title').text\n",
    " print(\"Extracted Title:\", title)\n",
    "# Store the extracted title to a file\n",
    "with open('stored_titles.txt', 'w', encoding='utf-8') as file:\n",
    " for article in root.findall('article'):\n",
    "     tittle = article.find('title').text\n",
    "     file.write(title + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0070c70-eb98-4cd3-9f57-4a1d69e9789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\azif\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb08758d-59ef-4abf-87b9-d276557aeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9afab011-fcb1-475d-bafc-2e4ccf162f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n",
      " This is a sample PDF document.  \n",
      "AI is transforming industries and automation.  \n"
     ]
    }
   ],
   "source": [
    "# Read the PDF file\n",
    "with open('document.pdf', 'rb') as file:\n",
    " reader = PyPDF2.PdfReader(file)\n",
    " text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "# Print the extracted text\n",
    "print(\"Extracted PDF Text:\\n\", text)\n",
    "# Store the extracted text in a file\n",
    "with open('stored_pdf_text.txt', 'w', encoding='utf-8') as output:\n",
    " output.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba95832d-7b66-4200-bc38-5fdb31610a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted PDF Text:\n",
      " Business Proposal  \n",
      "The Revolution is Coming  \n",
      "Leverage agile frameworks to provide a robust synopsis for high level  \n",
      "overviews. Iterative approaches to corporate strategy foster collaborative  \n",
      "thinking to further the overall value proposition. Organically grow the  \n",
      "holistic world view of disruptive innovation via workplace diversity and  \n",
      "empowerment.  \n",
      "Bring to the table win -win survival strategies to ensure proactive  \n",
      "domination. At the end of the day, going forward, a new normal that has  \n",
      "evolved from generation X is on the runway heading towards a streamlined  \n",
      "cloud solution. User generated content in real -time will have multi ple \n",
      "touchpoints for offshoring.  \n",
      "Capitalize on low hanging fruit to identify a ballpark value added activity to  \n",
      "beta test. Override the digital divide with additional clickthroughs from  \n",
      "DevOps. Nanotechnology immersion along the information highway will  \n",
      "close the loop on focusing solely on the bottom line.  \n",
      "Podcasting operational change management inside of workflows to  \n",
      "establish a framework. Taking seamless key performance indicators offline  \n",
      "to maximise the long tail. Keeping your eye on the ball while perfo rming a  \n",
      "deep dive on the start -up mentality to derive convergence on crossplatform  \n",
      "integration.  \n",
      "Collaboratively administrate empowered markets via plug -and-play \n",
      "networks. Dynamically procrastinate B2C users after installed base  \n",
      "benefits. Dramatically visua lize customer directed convergence without  \n",
      "revolutionary ROI.  \n",
      "Efficiently unleash cross -media information without cross -media value.  \n",
      "Quickly maximize timely deliverables for real -time schemas. Dramatically  \n",
      "maintain clicks -and-mortar solutions without funct ional solutio ns. \n",
      "  \n",
      "AUTHORS:  \n",
      "Amy Baker, Finance Chair, x345, abaker@ourcompany.com  \n",
      "Chris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \n",
      "Erin Freeman, Sr. VP, x879, efreeman@ourcompany.com  \n"
     ]
    }
   ],
   "source": [
    "# Read the PDF file\n",
    "with open('Business_Proposal.pdf', 'rb') as file:\n",
    " reader = PyPDF2.PdfReader(file)\n",
    " text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "# Print the extracted text\n",
    "print(\"Extracted PDF Text:\\n\", text)\n",
    "# Store the extracted text in a file\n",
    "with open('business_proposal_all.txt', 'w', encoding='utf-8') as output:\n",
    " output.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cc9a767-6c69-4cfc-bbe0-eb5b2bc28778",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1761044575.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    Page2 = reader.pages[1]page.extract_text()\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Read the PDF file\n",
    "with open('Business_Proposal.pdf', 'rb') as file:\n",
    " reader = PyPDF2.PdfReader(file)\n",
    " Page2 = reader.pages[1]page.extract_text()\n",
    "print(Page2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8997db3-2293-49eb-bb9f-f6e55d18ca32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTHORS:  \n",
      "Amy Baker, Finance Chair, x345, abaker@ourcompany.com  \n",
      "Chris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \n",
      "Erin Freeman, Sr. VP, x879, efreeman@ourcompany.com  \n"
     ]
    }
   ],
   "source": [
    "# Read the PDF file\n",
    "with open('Business_Proposal.pdf', 'rb') as file:\n",
    " reader = PyPDF2.PdfReader(file)\n",
    " Page2 = reader.pages[1].extract_text()\n",
    "print(Page2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928b1c56-3788-4fd7-b897-6e0e7e8db128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
