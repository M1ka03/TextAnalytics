{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab073aeb-9d7d-4b66-88d1-bddad939dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f358f151-b2a7-44da-897c-ad40a8c29e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2853973252.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpip install gensim\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n",
    "\n",
    "#Madam, madam tak solve lagi masalah saya where I cannot download gensim. Dari week lab 8 haritu. Mintak maaf ye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c09a924a-0aa3-4881-92a7-894c3e293a47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'triu' from 'scipy.linalg.special_matrices' (C:\\Users\\mnkam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\linalg\\special_matrices.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gensim\\matutils.py:30\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triu\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'triu' from 'scipy.linalg.basic' (C:\\Users\\mnkam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\linalg\\basic.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m corpora\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LdaModel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gensim\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package contains interfaces and functionality to compute pair-wise document\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03msimilarities within a corpus of documents.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils, matutils, interfaces, corpora, models, similarities\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gensim\\matutils.py:32\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbasic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triu\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecial_matrices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triu\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m triu_indices\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'triu' from 'scipy.linalg.special_matrices' (C:\\Users\\mnkam\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\linalg\\special_matrices.py)"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.model import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa215fed-cafb-46c9-83cb-e7478643edcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (3591456668.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnltk.download(‘stopwords’)\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "nltk.download(‘stopwords’)\n",
    "nltk.download(‘punkt’)\n",
    "nltk.download(‘wordnet’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c76245-a792-43b0-b592-e946e3a12d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "\"Rafael Nadal Joins Roger Federer in Missing U.S. Open\", \"Rafael Nadal Is Out of the Australian Open\",\n",
    "\"Biden Announces Virus Measures\",\n",
    "\"Biden's Virus Plans Meet Reality\",\n",
    "\"Where Biden's Virus Plan Stands\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b3820b7-3443-48bd-9ad7-5ea437261983",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '‘' (U+2018) (3543330608.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mstop_words = set(stopwords.word(‘english’))\u001b[39m\n                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '‘' (U+2018)\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.word(‘english’))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98178641-47b9-4031-864e-3fcd362c53bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (556204582.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef preprocess_text(text)\u001b[39m\n                             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text)\n",
    "\ttokens = word_tokenize\n",
    "\ttokens = [token for token in tokens if token.isalnum()]\n",
    "\ttokens = [token for token in tokens if token not in stop_words]\n",
    "\ttokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\treturn tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e8b675-65e7-4c66-8c7b-2e0d7ae66608",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m preprocessed_documents = [\u001b[43mpreprocess_text\u001b[49m(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m      2\u001b[39m preprocessed_documents\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "814b0a18-37a5-4135-a2df-06184c0d6c7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dictionary = \u001b[43mcorpora\u001b[49m.Dictionary(preprocessed_documents)\n\u001b[32m      2\u001b[39m corpus = [dictionary.doc2bow(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m preprocessed_documents]\n",
      "\u001b[31mNameError\u001b[39m: name 'corpora' is not defined"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fbcc9a0-4c3f-4705-ac7d-ef4246bd1c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LdaModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#corpus: bag-of-words representation of the documents\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#num_topics: number of topics to be extracted by the model\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#id2word=dictionary: dictionary mapping from word IDs to word\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#passes: number of passes through the corpus during training \u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Train an LDA model on the corpus with 4 topics using Gensim’s LdaModel class\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m lda_model = \u001b[43mLdaModel\u001b[49m(corpus, num_topics=\u001b[32m2\u001b[39m, id2word=dictionary, passes=\u001b[32m15\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'LdaModel' is not defined"
     ]
    }
   ],
   "source": [
    "#corpus: bag-of-words representation of the documents\n",
    "#num_topics: number of topics to be extracted by the model\n",
    "#id2word=dictionary: dictionary mapping from word IDs to word\n",
    "#passes: number of passes through the corpus during training \n",
    "# Train an LDA model on the corpus with 4 topics using Gensim’s LdaModel class\n",
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3800dfe-e9e1-4277-818c-44303b311be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0733183-affd-474a-b830-6a70436deecc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m (\u001b[43mpreprocessed_documents\u001b[49m):\n\u001b[32m      2\u001b[39m \tbow = dictionary.doc2bow(doc)\n\u001b[32m      3\u001b[39m \ttopics = lda_model.get_document_topics(bow)\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocessed_documents' is not defined"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate (preprocessed_documents):\n",
    "\tbow = dictionary.doc2bow(doc)\n",
    "\ttopics = lda_model.get_document_topics(bow)\n",
    "\tdominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "\tarticle_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b234216f-f503-41ca-a7d7-9f0435fbc758",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '“' (U+201C) (3495364012.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf = pd.DataFrame({“Article”: documents, “Topic”: article_labels})\u001b[39m\n                       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '“' (U+201C)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({“Article”: documents, “Topic”: article_labels})\n",
    "\n",
    "print(“Table with Articles and Topic: ”)\n",
    "print(df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "794528c6-80c4-4a3d-87cc-0ccbcbcc7e8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '“' (U+201C) (2023202729.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(“Top Terms for Each Topic:”)\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character '“' (U+201C)\n"
     ]
    }
   ],
   "source": [
    "print(“Top Terms for Each Topic:”)\n",
    "for idx, topic in lda_model.print_topics():\n",
    "\tprint(f”Topic {idx}:“)\n",
    "\tterms = [term.strip() for term in topic.split(“+”)]\n",
    "\tfor term in terms:\n",
    "\t\tweight, word = term.split(*)\n",
    "\t\tprint(f”- {word.strip()} (weight:  {weight.strip()})”_\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8de6bd-9bce-4fcf-8e11-8034a404cbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
